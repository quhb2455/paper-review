{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a60d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cbd11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class patch_embedding(nn.Module) :\n",
    "    def __init__(self, patch_size, img_size, embed_size) :\n",
    "        super(patch_embedding, self).__init__()\n",
    "        \n",
    "        self.patch_embedding = nn.Conv2d(3, embed_size, \n",
    "                                         kernel_size=patch_size, \n",
    "                                         stride=patch_size)\n",
    "        # cls token을 패치 앞에 하나 더 붙여줌\n",
    "        # ex) 9개의 패치로 이미지를 나누면 앞에 cls token이 붙어 최종적으로 10개의 패치가 되는 셈\n",
    "        self.cls_token = nn.Parameter(torch.rand(1,1,embed_size))\n",
    "        \n",
    "        # cls token 1개가 더 붙었기 때문에 총 patch 개수에 + 1을 해줌\n",
    "        self.position = nn.Parameter(torch.rand((img_size//patch_size)**2 + 1, embed_size))\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        x = self.patch_embedding(x)\n",
    "        x = x.flatten(2)\n",
    "        x = x.transpose(2,1)\n",
    "\n",
    "        ct = self.cls_token.repeat(x.shape[0], 1, 1)\n",
    "        x = torch.cat([ct, x],dim=1)\n",
    "        x += self.position\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d02362c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "data = torch.rand(5,3,224,224)\n",
    "pe = patch_embedding(16, 224, 768)\n",
    "y = pe(data)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f47a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_head_attention(nn.Module) :\n",
    "    def __init__(self, embed_size, num_head, dropout_rate=0.1) :\n",
    "        super(multi_head_attention, self).__init__()\n",
    "        \n",
    "        self.q = nn.Linear(embed_size, embed_size)\n",
    "        self.k = nn.Linear(embed_size, embed_size)\n",
    "        self.v = nn.Linear(embed_size, embed_size)\n",
    "        \n",
    "        self.fc = nn.Linear(embed_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.num_head = num_head\n",
    "        self.embed_size = embed_size\n",
    "    \n",
    "    # 내가 쓴 노션(study list/Trasformer/Q,K,V 벡터 얻기)에 보면 \n",
    "    # QKV는 각각 d / num_head 차원을 가져야 한다고 나와있음\n",
    "    # 여기서는 d 가 embed_size 임\n",
    "    # 따라서 (batch, patch_num, embed_size)에서 embed_size를 embed_size/num_head로 변경해야함\n",
    "    # (batch, patch_num, num_head, embed_size//num_head)로 표현가능\n",
    "    # 행렬을 이용하여 병렬로 처리 할 것이기 때문에\n",
    "    # (batch, num_head, patch_num, embed_size//num_head)로 표현 함\n",
    "    # (patch_num, embed_size//num_head)가 num_head 개수 만큼 있어야 1개의 값을 완성 한다고 보면됨\n",
    "    def qkv_reshape(self, value, num_head) :\n",
    "        b, n, emb = value.size()\n",
    "        dim = emb // num_head\n",
    "        return value.view(b, num_head, n, dim)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        q = self.qkv_reshape(self.q(x), self.num_head)\n",
    "        k = self.qkv_reshape(self.k(x), self.num_head)\n",
    "        v = self.qkv_reshape(self.v(x), self.num_head)\n",
    "        \n",
    "        qk = torch.matmul(q, k.transpose(3,2))\n",
    "        # torch.sqrt를 쓰니까 tensor가 아니라고 에러남\n",
    "        att = F.softmax(qk / (self.embed_size ** (1/2)), dim=-1)\n",
    "        att = torch.matmul(att, v)\n",
    "        \n",
    "        b, h, n, d = att.size()\n",
    "        x = att.view(b, n, h*d)\n",
    "        x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        print(\"DONE - MHA\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0960f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE - MHA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 197, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.rand(5, 197, 768)\n",
    "mha = multi_head_attention(768, 8, dropout_rate=0.1)\n",
    "y = mha(data)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23f733e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class skip_connection(nn.Module) :\n",
    "    def __init__(self, fn) :\n",
    "        super(skip_connection, self).__init__()\n",
    "        self.fn = fn\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip = x\n",
    "        x = self.fn(x)\n",
    "        x += skip\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c244a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE - MHA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 197, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.rand(5, 197, 768)\n",
    "sc = skip_connection(mha)\n",
    "y = sc(data)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b02ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module) :\n",
    "    def __init__(self, embed_size, expansion, dropout_rate):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(embed_size, embed_size*expansion)\n",
    "        self.fc2 = nn.Linear(embed_size*expansion, embed_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "809c0987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 197, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.rand(5, 197, 768)\n",
    "mlp = MLP(768, 3, 0.1)\n",
    "y = mlp(data)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03596066",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module) :\n",
    "    def __init__(self, \n",
    "                 embed_size, \n",
    "                 num_head, \n",
    "                 expansion, \n",
    "                 dropout_rate):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        \n",
    "        self.skip_connection1 = skip_connection(\n",
    "            nn.Sequential(\n",
    "                nn.LayerNorm(embed_size),\n",
    "                multi_head_attention(embed_size, num_head, dropout_rate=0.1)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.skip_connection2 = skip_connection(\n",
    "            nn.Sequential(\n",
    "                nn.LayerNorm(embed_size),\n",
    "                MLP(embed_size, expansion, dropout_rate=0.1)\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        x = self.skip_connection1(x)\n",
    "        x = self.skip_connection2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa3440df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE - MHA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 196, 672])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.rand(5, 196, 672)\n",
    "eb = EncoderBlock(672, 7, 4, 0.1)\n",
    "y = eb(data)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2296cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_Head(nn.Module) :\n",
    "    def __init__(self, embed_size, num_classes):\n",
    "        super(Classifier_Head, self).__init__()\n",
    "        \n",
    "        self.avgpool1d = nn.AdaptiveAvgPool1d((1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(embed_size),\n",
    "            nn.Linear(embed_size, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        # 현재 x shape 은 (batch, num_patch, embed_size)임\n",
    "        # 여기서 num_patch를 기준으로 avg pool을 해준 후 fc를 통과시킴\n",
    "        # avgpool2d를 사용하면 (num_path, embed_size)를 기준으로 계산이 되서\n",
    "        # 결과값이 (batch, ?, ?) 이런식으로 나옴. 여기서 \"?\"는 pool2d의 ouput 설정 값\n",
    "        # 만약 nn.AdaptiveAvgPool2d((3,3))으로하면 (batch, 3, 3)으로 나옴\n",
    "        # num_patch를 기준으로 avgpool1d를 사용하기 위해 transpose로  (batch, embed_size, num_patch)로 변경해줌\n",
    "        # 그 후에 avgpool1d를 적용하여 (batch, embed_size, 1)로 만들어주고 squeeze로 1을 없애줌\n",
    "        # 결과적으로 transpose -> avgpool1d -> squeeze(2) -> shape:(batch, embed_size)가 됨\n",
    "        x = x.transpose(2,1)\n",
    "        x = self.avgpool1d(x).squeeze(2)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a4f9366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.rand(5, 196, 672)\n",
    "ch = Classifier_Head(672, 10)\n",
    "y = ch(data)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "680bc829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 1])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "data = torch.rand(3, 3, 4)\n",
    "# print(data)\n",
    "avg = nn.AdaptiveAvgPool1d((1))\n",
    "y = avg(data)\n",
    "print(y.shape)\n",
    "# print(y)\n",
    "y = y.squeeze(2)\n",
    "print(y.shape)\n",
    "# print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b49d613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VIT(nn.Module) :\n",
    "    def __init__(self, \n",
    "                 patch_size=16, \n",
    "                 img_size=224, \n",
    "                 embed_size=768, \n",
    "                 num_head = 8,\n",
    "                 expansion = 4,\n",
    "                 dropout_rate = 0.1,\n",
    "                 encoder_depth = 12,\n",
    "                 num_classes = 10) :\n",
    "        super(VIT, self).__init__()\n",
    "\n",
    "        self.PatchEmbedding = patch_embedding(patch_size, img_size, embed_size)\n",
    "        self.EncoderBlocks = self.make_layers(encoder_depth, embed_size, num_head, expansion, dropout_rate)\n",
    "        self.ClassifierHead = Classifier_Head(embed_size, num_classes)\n",
    "        \n",
    "    def make_layers(self, encoder_depth, *args):\n",
    "        layers = []\n",
    "        for _ in range(0, encoder_depth) :\n",
    "            layers.append(EncoderBlock(*args))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        x = self.PatchEmbedding(x)\n",
    "        x = self.EncoderBlocks(x)\n",
    "        x = self.ClassifierHead(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "197ce596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE - MHA\n",
      "DONE - MHA\n",
      "DONE - MHA\n",
      "DONE - MHA\n",
      "DONE - MHA\n",
      "DONE - MHA\n",
      "DONE - MHA\n",
      "DONE - MHA\n",
      "DONE - MHA\n",
      "DONE - MHA\n",
      "DONE - MHA\n",
      "DONE - MHA\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 768, 14, 14]         590,592\n",
      "   patch_embedding-2             [-1, 197, 768]               0\n",
      "         LayerNorm-3             [-1, 197, 768]           1,536\n",
      "            Linear-4             [-1, 197, 768]         590,592\n",
      "            Linear-5             [-1, 197, 768]         590,592\n",
      "            Linear-6             [-1, 197, 768]         590,592\n",
      "            Linear-7             [-1, 197, 768]         590,592\n",
      "           Dropout-8             [-1, 197, 768]               0\n",
      "multi_head_attention-9             [-1, 197, 768]               0\n",
      "  skip_connection-10             [-1, 197, 768]               0\n",
      "        LayerNorm-11             [-1, 197, 768]           1,536\n",
      "           Linear-12            [-1, 197, 3072]       2,362,368\n",
      "             GELU-13            [-1, 197, 3072]               0\n",
      "           Linear-14             [-1, 197, 768]       2,360,064\n",
      "          Dropout-15             [-1, 197, 768]               0\n",
      "              MLP-16             [-1, 197, 768]               0\n",
      "  skip_connection-17             [-1, 197, 768]               0\n",
      "     EncoderBlock-18             [-1, 197, 768]               0\n",
      "        LayerNorm-19             [-1, 197, 768]           1,536\n",
      "           Linear-20             [-1, 197, 768]         590,592\n",
      "           Linear-21             [-1, 197, 768]         590,592\n",
      "           Linear-22             [-1, 197, 768]         590,592\n",
      "           Linear-23             [-1, 197, 768]         590,592\n",
      "          Dropout-24             [-1, 197, 768]               0\n",
      "multi_head_attention-25             [-1, 197, 768]               0\n",
      "  skip_connection-26             [-1, 197, 768]               0\n",
      "        LayerNorm-27             [-1, 197, 768]           1,536\n",
      "           Linear-28            [-1, 197, 3072]       2,362,368\n",
      "             GELU-29            [-1, 197, 3072]               0\n",
      "           Linear-30             [-1, 197, 768]       2,360,064\n",
      "          Dropout-31             [-1, 197, 768]               0\n",
      "              MLP-32             [-1, 197, 768]               0\n",
      "  skip_connection-33             [-1, 197, 768]               0\n",
      "     EncoderBlock-34             [-1, 197, 768]               0\n",
      "        LayerNorm-35             [-1, 197, 768]           1,536\n",
      "           Linear-36             [-1, 197, 768]         590,592\n",
      "           Linear-37             [-1, 197, 768]         590,592\n",
      "           Linear-38             [-1, 197, 768]         590,592\n",
      "           Linear-39             [-1, 197, 768]         590,592\n",
      "          Dropout-40             [-1, 197, 768]               0\n",
      "multi_head_attention-41             [-1, 197, 768]               0\n",
      "  skip_connection-42             [-1, 197, 768]               0\n",
      "        LayerNorm-43             [-1, 197, 768]           1,536\n",
      "           Linear-44            [-1, 197, 3072]       2,362,368\n",
      "             GELU-45            [-1, 197, 3072]               0\n",
      "           Linear-46             [-1, 197, 768]       2,360,064\n",
      "          Dropout-47             [-1, 197, 768]               0\n",
      "              MLP-48             [-1, 197, 768]               0\n",
      "  skip_connection-49             [-1, 197, 768]               0\n",
      "     EncoderBlock-50             [-1, 197, 768]               0\n",
      "        LayerNorm-51             [-1, 197, 768]           1,536\n",
      "           Linear-52             [-1, 197, 768]         590,592\n",
      "           Linear-53             [-1, 197, 768]         590,592\n",
      "           Linear-54             [-1, 197, 768]         590,592\n",
      "           Linear-55             [-1, 197, 768]         590,592\n",
      "          Dropout-56             [-1, 197, 768]               0\n",
      "multi_head_attention-57             [-1, 197, 768]               0\n",
      "  skip_connection-58             [-1, 197, 768]               0\n",
      "        LayerNorm-59             [-1, 197, 768]           1,536\n",
      "           Linear-60            [-1, 197, 3072]       2,362,368\n",
      "             GELU-61            [-1, 197, 3072]               0\n",
      "           Linear-62             [-1, 197, 768]       2,360,064\n",
      "          Dropout-63             [-1, 197, 768]               0\n",
      "              MLP-64             [-1, 197, 768]               0\n",
      "  skip_connection-65             [-1, 197, 768]               0\n",
      "     EncoderBlock-66             [-1, 197, 768]               0\n",
      "        LayerNorm-67             [-1, 197, 768]           1,536\n",
      "           Linear-68             [-1, 197, 768]         590,592\n",
      "           Linear-69             [-1, 197, 768]         590,592\n",
      "           Linear-70             [-1, 197, 768]         590,592\n",
      "           Linear-71             [-1, 197, 768]         590,592\n",
      "          Dropout-72             [-1, 197, 768]               0\n",
      "multi_head_attention-73             [-1, 197, 768]               0\n",
      "  skip_connection-74             [-1, 197, 768]               0\n",
      "        LayerNorm-75             [-1, 197, 768]           1,536\n",
      "           Linear-76            [-1, 197, 3072]       2,362,368\n",
      "             GELU-77            [-1, 197, 3072]               0\n",
      "           Linear-78             [-1, 197, 768]       2,360,064\n",
      "          Dropout-79             [-1, 197, 768]               0\n",
      "              MLP-80             [-1, 197, 768]               0\n",
      "  skip_connection-81             [-1, 197, 768]               0\n",
      "     EncoderBlock-82             [-1, 197, 768]               0\n",
      "        LayerNorm-83             [-1, 197, 768]           1,536\n",
      "           Linear-84             [-1, 197, 768]         590,592\n",
      "           Linear-85             [-1, 197, 768]         590,592\n",
      "           Linear-86             [-1, 197, 768]         590,592\n",
      "           Linear-87             [-1, 197, 768]         590,592\n",
      "          Dropout-88             [-1, 197, 768]               0\n",
      "multi_head_attention-89             [-1, 197, 768]               0\n",
      "  skip_connection-90             [-1, 197, 768]               0\n",
      "        LayerNorm-91             [-1, 197, 768]           1,536\n",
      "           Linear-92            [-1, 197, 3072]       2,362,368\n",
      "             GELU-93            [-1, 197, 3072]               0\n",
      "           Linear-94             [-1, 197, 768]       2,360,064\n",
      "          Dropout-95             [-1, 197, 768]               0\n",
      "              MLP-96             [-1, 197, 768]               0\n",
      "  skip_connection-97             [-1, 197, 768]               0\n",
      "     EncoderBlock-98             [-1, 197, 768]               0\n",
      "        LayerNorm-99             [-1, 197, 768]           1,536\n",
      "          Linear-100             [-1, 197, 768]         590,592\n",
      "          Linear-101             [-1, 197, 768]         590,592\n",
      "          Linear-102             [-1, 197, 768]         590,592\n",
      "          Linear-103             [-1, 197, 768]         590,592\n",
      "         Dropout-104             [-1, 197, 768]               0\n",
      "multi_head_attention-105             [-1, 197, 768]               0\n",
      " skip_connection-106             [-1, 197, 768]               0\n",
      "       LayerNorm-107             [-1, 197, 768]           1,536\n",
      "          Linear-108            [-1, 197, 3072]       2,362,368\n",
      "            GELU-109            [-1, 197, 3072]               0\n",
      "          Linear-110             [-1, 197, 768]       2,360,064\n",
      "         Dropout-111             [-1, 197, 768]               0\n",
      "             MLP-112             [-1, 197, 768]               0\n",
      " skip_connection-113             [-1, 197, 768]               0\n",
      "    EncoderBlock-114             [-1, 197, 768]               0\n",
      "       LayerNorm-115             [-1, 197, 768]           1,536\n",
      "          Linear-116             [-1, 197, 768]         590,592\n",
      "          Linear-117             [-1, 197, 768]         590,592\n",
      "          Linear-118             [-1, 197, 768]         590,592\n",
      "          Linear-119             [-1, 197, 768]         590,592\n",
      "         Dropout-120             [-1, 197, 768]               0\n",
      "multi_head_attention-121             [-1, 197, 768]               0\n",
      " skip_connection-122             [-1, 197, 768]               0\n",
      "       LayerNorm-123             [-1, 197, 768]           1,536\n",
      "          Linear-124            [-1, 197, 3072]       2,362,368\n",
      "            GELU-125            [-1, 197, 3072]               0\n",
      "          Linear-126             [-1, 197, 768]       2,360,064\n",
      "         Dropout-127             [-1, 197, 768]               0\n",
      "             MLP-128             [-1, 197, 768]               0\n",
      " skip_connection-129             [-1, 197, 768]               0\n",
      "    EncoderBlock-130             [-1, 197, 768]               0\n",
      "       LayerNorm-131             [-1, 197, 768]           1,536\n",
      "          Linear-132             [-1, 197, 768]         590,592\n",
      "          Linear-133             [-1, 197, 768]         590,592\n",
      "          Linear-134             [-1, 197, 768]         590,592\n",
      "          Linear-135             [-1, 197, 768]         590,592\n",
      "         Dropout-136             [-1, 197, 768]               0\n",
      "multi_head_attention-137             [-1, 197, 768]               0\n",
      " skip_connection-138             [-1, 197, 768]               0\n",
      "       LayerNorm-139             [-1, 197, 768]           1,536\n",
      "          Linear-140            [-1, 197, 3072]       2,362,368\n",
      "            GELU-141            [-1, 197, 3072]               0\n",
      "          Linear-142             [-1, 197, 768]       2,360,064\n",
      "         Dropout-143             [-1, 197, 768]               0\n",
      "             MLP-144             [-1, 197, 768]               0\n",
      " skip_connection-145             [-1, 197, 768]               0\n",
      "    EncoderBlock-146             [-1, 197, 768]               0\n",
      "       LayerNorm-147             [-1, 197, 768]           1,536\n",
      "          Linear-148             [-1, 197, 768]         590,592\n",
      "          Linear-149             [-1, 197, 768]         590,592\n",
      "          Linear-150             [-1, 197, 768]         590,592\n",
      "          Linear-151             [-1, 197, 768]         590,592\n",
      "         Dropout-152             [-1, 197, 768]               0\n",
      "multi_head_attention-153             [-1, 197, 768]               0\n",
      " skip_connection-154             [-1, 197, 768]               0\n",
      "       LayerNorm-155             [-1, 197, 768]           1,536\n",
      "          Linear-156            [-1, 197, 3072]       2,362,368\n",
      "            GELU-157            [-1, 197, 3072]               0\n",
      "          Linear-158             [-1, 197, 768]       2,360,064\n",
      "         Dropout-159             [-1, 197, 768]               0\n",
      "             MLP-160             [-1, 197, 768]               0\n",
      " skip_connection-161             [-1, 197, 768]               0\n",
      "    EncoderBlock-162             [-1, 197, 768]               0\n",
      "       LayerNorm-163             [-1, 197, 768]           1,536\n",
      "          Linear-164             [-1, 197, 768]         590,592\n",
      "          Linear-165             [-1, 197, 768]         590,592\n",
      "          Linear-166             [-1, 197, 768]         590,592\n",
      "          Linear-167             [-1, 197, 768]         590,592\n",
      "         Dropout-168             [-1, 197, 768]               0\n",
      "multi_head_attention-169             [-1, 197, 768]               0\n",
      " skip_connection-170             [-1, 197, 768]               0\n",
      "       LayerNorm-171             [-1, 197, 768]           1,536\n",
      "          Linear-172            [-1, 197, 3072]       2,362,368\n",
      "            GELU-173            [-1, 197, 3072]               0\n",
      "          Linear-174             [-1, 197, 768]       2,360,064\n",
      "         Dropout-175             [-1, 197, 768]               0\n",
      "             MLP-176             [-1, 197, 768]               0\n",
      " skip_connection-177             [-1, 197, 768]               0\n",
      "    EncoderBlock-178             [-1, 197, 768]               0\n",
      "       LayerNorm-179             [-1, 197, 768]           1,536\n",
      "          Linear-180             [-1, 197, 768]         590,592\n",
      "          Linear-181             [-1, 197, 768]         590,592\n",
      "          Linear-182             [-1, 197, 768]         590,592\n",
      "          Linear-183             [-1, 197, 768]         590,592\n",
      "         Dropout-184             [-1, 197, 768]               0\n",
      "multi_head_attention-185             [-1, 197, 768]               0\n",
      " skip_connection-186             [-1, 197, 768]               0\n",
      "       LayerNorm-187             [-1, 197, 768]           1,536\n",
      "          Linear-188            [-1, 197, 3072]       2,362,368\n",
      "            GELU-189            [-1, 197, 3072]               0\n",
      "          Linear-190             [-1, 197, 768]       2,360,064\n",
      "         Dropout-191             [-1, 197, 768]               0\n",
      "             MLP-192             [-1, 197, 768]               0\n",
      " skip_connection-193             [-1, 197, 768]               0\n",
      "    EncoderBlock-194             [-1, 197, 768]               0\n",
      "AdaptiveAvgPool1d-195               [-1, 768, 1]               0\n",
      "       LayerNorm-196                  [-1, 768]           1,536\n",
      "          Linear-197                   [-1, 10]           7,690\n",
      " Classifier_Head-198                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 85,654,282\n",
      "Trainable params: 85,654,282\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 307.05\n",
      "Params size (MB): 326.75\n",
      "Estimated Total Size (MB): 634.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = VIT()\n",
    "summary(model, (3,224,224),device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed6ecbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type :  <class 'tuple'>\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "def a(z, *args) :\n",
    "    print(\"type : \", type(args))\n",
    "    return b(*args)\n",
    "\n",
    "def b(a,b,c) :\n",
    "    return a+b+c\n",
    "print(a(12, 5, 3, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
