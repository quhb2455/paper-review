{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1e5bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import albumentations as A\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from itertools import permutations\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec7fd90",
   "metadata": {},
   "source": [
    "## Model - AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773ec7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module) :\n",
    "    def __init__(self, \n",
    "                 first_in=3, \n",
    "                 first_stride=4, \n",
    "                 dropout_rate=0.5, \n",
    "                 in_feature=256*6*6,\n",
    "                 out_feature=4608,\n",
    "                 num_classes=1000\n",
    "                ) :\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=first_in, \n",
    "                      out_channels=96, \n",
    "                      kernel_size=11, \n",
    "                      padding=2, \n",
    "                      stride=first_stride),\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, \n",
    "                                 k=2,    \n",
    "                                 alpha=0.0001, \n",
    "                                 beta=0.75),\n",
    "            nn.MaxPool2d(kernel_size=3, \n",
    "                        stride=2),\n",
    "        )\n",
    "        \n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, \n",
    "                     out_channels=256,\n",
    "                      padding=2,\n",
    "                      kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, \n",
    "                                 k=2,    \n",
    "                                 alpha=0.0001, \n",
    "                                 beta=0.75),\n",
    "            nn.MaxPool2d(kernel_size=3, \n",
    "                        stride=2),\n",
    "        )\n",
    "        \n",
    "        self.conv_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, \n",
    "                     out_channels=384,\n",
    "                      padding=1,\n",
    "                      kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.conv_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=384, \n",
    "                     out_channels=384,\n",
    "                      padding=1,\n",
    "                      kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.conv_5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=384, \n",
    "                     out_channels=256,\n",
    "                      padding=1,\n",
    "                      kernel_size=3,\n",
    "                     ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, \n",
    "                         stride=2),\n",
    "        )\n",
    "                \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            self.conv_1, \n",
    "            self.conv_2, \n",
    "            self.conv_3, \n",
    "            self.conv_4, \n",
    "            self.conv_5, \n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(in_feature, out_feature),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(out_feature, out_feature),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(out_feature, num_classes),\n",
    "        )\n",
    "\n",
    "        \n",
    "        for idx, layers in enumerate(self.conv_layers):\n",
    "            self.initialization(idx, layers)\n",
    "\n",
    "        self.initialization('fc', self.fc_layers)\n",
    "\n",
    "    def initialization(self, idx, layers) :\n",
    "        for layer in layers :\n",
    "            if 'weight' in dir(layer):\n",
    "                nn.init.normal_(layer.weight, mean=0, std=0.01)                \n",
    "                if idx in ['fc', 1, 3, 4] :\n",
    "                    nn.init.constant_(layer.bias, 1)\n",
    "                elif idx in [0, 2] :\n",
    "                    nn.init.constant_(layer.bias, 0)    \n",
    "                    \n",
    "    def forward(self, x) :\n",
    "        x = self.conv_layers(x)\n",
    "        # x = x.contiguous().view(-1) \n",
    "\n",
    "        x = x.flatten(1)\n",
    "\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce37eab",
   "metadata": {},
   "source": [
    "## Model - CFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11577b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFN(nn.Module) :\n",
    "    def __init__(self, \n",
    "                 in_channel=27, \n",
    "                 strd=2, \n",
    "                 in_feature=256*3*3, \n",
    "                 out_feature=4608, \n",
    "                 num_classes=69) :\n",
    "        super(CFN, self).__init__()\n",
    "        self.alexnet = AlexNet(first_in=in_channel, \n",
    "                               first_stride=strd, \n",
    "                               in_feature=in_feature, \n",
    "                               out_feature=out_feature\n",
    "                              )\n",
    "        # alexnet 논문에 나와있는 방법으로 초기화한 layer들을 가져옴\n",
    "        self.conv_layers = self.alexnet.conv_layers\n",
    "        self.fc6 = self.alexnet.fc_layers[0]\n",
    "        \n",
    "        # fc7, fc8, output 포함\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(out_feature, 4096), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.alexnet.initialization('fc', self.classifier)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc6(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c7dbfd",
   "metadata": {},
   "source": [
    "## puzzle pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ffe7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class jigsaw_pipeline() :\n",
    "    def __init__(self, color_jitter=False) :\n",
    "        self.color_jitter = color_jitter\n",
    "    \n",
    "    def __call__(self, img) :\n",
    "        h, w, c = img.shape\n",
    "        \n",
    "        # step 1. resize width or height to 256 with preserve the original aspect ratio.\n",
    "        if h < w :\n",
    "            resized_w = int(w / h * 256)\n",
    "            img = cv2.resize(img, (256 , resized_w))\n",
    "\n",
    "        elif w <= h :\n",
    "            resized_h = int(h / w * 256)\n",
    "            img = cv2.resize(img, (resized_h, 256))\n",
    "        \n",
    "        # step 2. Random crop size 225 x 225\n",
    "        img = A.RandomCrop(225, 225)(image = img)['image']\n",
    "        \n",
    "        # step 3 and 4. split 3 x 3 grid of 75 x 75 pixels tiles and random crop 64 x 64\n",
    "        for i in range(3) :\n",
    "            for j in range(3) :\n",
    "                crop_img = img[i*75 : (i * 75) + 75, j*75 : (j * 75) + 75, :]\n",
    "                \n",
    "                if i == 0 and j == 0 :    \n",
    "                    tile_img = A.RandomCrop(64, 64)(image = crop_img)['image']\n",
    "                else : \n",
    "                    tile_img = np.concatenate((tile_img, A.RandomCrop(64, 64)(image = crop_img)['image']),axis=2)\n",
    "        \n",
    "        return tile_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a24462",
   "metadata": {},
   "source": [
    "## Generate Permutation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54714ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutation_sets(number_permu_set=100, max_hamming=True, save=True) :\n",
    "\n",
    "    item = [i for i in range(1,10)]\n",
    "    permutate_items = np.array(list(permutations(item, 9)))\n",
    "    max_hamming = True\n",
    "\n",
    "    N = number_permu_set # permutation 개수\n",
    "    j = np.random.choice(len(permutate_items), 1, replace=False)\n",
    "\n",
    "    for i in tqdm(range(1, N+1)) :\n",
    "        if i == 1 :\n",
    "            p = np.array(permutate_items[j])\n",
    "        else : \n",
    "            hat_p = np.array(permutate_items[j]).reshape([1, -1])\n",
    "            p = np.concatenate([p, hat_p], axis=0)\n",
    "\n",
    "        permutate_items = np.delete(permutate_items, j, axis=0)\n",
    "        d = distance.cdist(p, permutate_items, metric='hamming').mean(axis=0)\n",
    "\n",
    "        if max_hamming == True :\n",
    "            j = np.argmax(d)\n",
    "        else : \n",
    "            j = np.argmin(d)\n",
    "            \n",
    "    if save :\n",
    "        np.save(f'permutation_{N}_sets.npy', p)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d81aa9",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6af1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JIGSAW_DATASET(Dataset) :\n",
    "    def __init__(self, img_list, permu_set) :\n",
    "        self.img_list = img_list\n",
    "        self.permu_set = permu_set\n",
    "        self.pipeline = jigsaw_pipeline()\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def shuffle_tiles(self, tile, permu):\n",
    "        shuffled_tile = np.zeros_like(tile)\n",
    "        for idx, num in enumerate(permu, start=1) :\n",
    "            shuffled_tile[:, :, (idx-1)*3 : idx*3] = tile[:, :, (num-1) * 3 : num * 3]\n",
    "        return shuffled_tile\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        img = cv2.imread(self.img_list[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.pipeline(img)\n",
    "        \n",
    "        permu_idx = np.random.randint(self.permu_set.shape[0])\n",
    "        permu = self.permu_set[permu_idx]\n",
    "        img = self.shuffle_tiles(img, permu)\n",
    "        \n",
    "        return torch.FloatTensor(img), torch.LongTensor(permu_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b1a9cff",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-yu9s42k6\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-19070a402290>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdl\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\torch-sub\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\torch-sub\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\torch-sub\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\torch-sub\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-97701476c0fe>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-yu9s42k6\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "ps = np.load('./permutation_30_sets.npy')\n",
    "jd = JIGSAW_DATASET('./data/1.jpg', ps)\n",
    "dl = DataLoader(jd)\n",
    "\n",
    "for img, idx in dl :\n",
    "    print(img.shape, idx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef68815",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7069c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Options = {\n",
    "    'permu_set_path' : './permutation_30_sets.npy',\n",
    "    'batch_size' : 16,\n",
    "    'epochs' : 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83cc84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26e957ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef587c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
