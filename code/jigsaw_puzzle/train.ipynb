{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1e5bf0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import albumentations as A\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from itertools import permutations\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from easydict  import EasyDict "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec7fd90",
   "metadata": {},
   "source": [
    "## Model - AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773ec7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module) :\n",
    "    def __init__(self, \n",
    "                 first_in=3, \n",
    "                 first_stride=4, \n",
    "                 dropout_rate=0.5, \n",
    "                 in_feature=256*6*6,\n",
    "                 out_feature=4608,\n",
    "                 num_classes=1000\n",
    "                ) :\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=first_in, \n",
    "                      out_channels=96, \n",
    "                      kernel_size=11, \n",
    "                      padding=2, \n",
    "                      stride=first_stride),\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, \n",
    "                                 k=2,    \n",
    "                                 alpha=0.0001, \n",
    "                                 beta=0.75),\n",
    "            nn.MaxPool2d(kernel_size=3, \n",
    "                        stride=2),\n",
    "        )\n",
    "        \n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, \n",
    "                     out_channels=256,\n",
    "                      padding=2,\n",
    "                      kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, \n",
    "                                 k=2,    \n",
    "                                 alpha=0.0001, \n",
    "                                 beta=0.75),\n",
    "            nn.MaxPool2d(kernel_size=3, \n",
    "                        stride=2),\n",
    "        )\n",
    "        \n",
    "        self.conv_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, \n",
    "                     out_channels=384,\n",
    "                      padding=1,\n",
    "                      kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.conv_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=384, \n",
    "                     out_channels=384,\n",
    "                      padding=1,\n",
    "                      kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.conv_5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=384, \n",
    "                     out_channels=256,\n",
    "                      padding=1,\n",
    "                      kernel_size=3,\n",
    "                     ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, \n",
    "                         stride=2),\n",
    "        )\n",
    "                \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            self.conv_1, \n",
    "            self.conv_2, \n",
    "            self.conv_3, \n",
    "            self.conv_4, \n",
    "            self.conv_5, \n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(in_feature, out_feature),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(out_feature, out_feature),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(out_feature, num_classes),\n",
    "        )\n",
    "\n",
    "        \n",
    "        for idx, layers in enumerate(self.conv_layers):\n",
    "            self.initialization(idx, layers)\n",
    "\n",
    "        self.initialization('fc', self.fc_layers)\n",
    "\n",
    "    def initialization(self, idx, layers) :\n",
    "        for layer in layers :\n",
    "            if 'weight' in dir(layer):\n",
    "                nn.init.normal_(layer.weight, mean=0, std=0.01)                \n",
    "                if idx in ['fc', 1, 3, 4] :\n",
    "                    nn.init.constant_(layer.bias.data, 1)\n",
    "                elif idx in [0, 2] :\n",
    "                    nn.init.constant_(layer.bias.data, 0)    \n",
    "                    \n",
    "    def forward(self, x) :\n",
    "        x = self.conv_layers(x)\n",
    "        # x = x.contiguous().view(-1) \n",
    "\n",
    "        x = x.flatten(1)\n",
    "\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce37eab",
   "metadata": {},
   "source": [
    "## Model - CFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11577b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFN(nn.Module) :\n",
    "    def __init__(self, \n",
    "                 in_channel=27, \n",
    "                 strd=2, \n",
    "                 in_feature=256*3*3, \n",
    "                 out_feature=4608, \n",
    "                 num_classes=69) :\n",
    "        super(CFN, self).__init__()\n",
    "        self.alexnet = AlexNet(first_in=in_channel, \n",
    "                               first_stride=strd, \n",
    "                               in_feature=in_feature, \n",
    "                               out_feature=out_feature\n",
    "                              )\n",
    "        # alexnet 논문에 나와있는 방법으로 초기화한 layer들을 가져옴\n",
    "        self.conv_layers = self.alexnet.conv_layers\n",
    "        self.fc6 = self.alexnet.fc_layers[0]\n",
    "        \n",
    "        # fc7, fc8, output 포함\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(out_feature, 4096), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.alexnet.initialization('fc', self.classifier)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc6(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c7dbfd",
   "metadata": {},
   "source": [
    "## puzzle pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ffe7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class jigsaw_pipeline() :\n",
    "    def __init__(self, normalize=True, color_jitter=False) :\n",
    "        self.color_jitter = color_jitter\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        if normalize :\n",
    "            self.transforms = A.Compose([\n",
    "                A.RandomCrop(64, 64),\n",
    "                A.Normalize()\n",
    "            ])\n",
    "        else : \n",
    "            self.transforms = A.Compose([\n",
    "                A.RandomCrop(64, 64)\n",
    "            ])\n",
    "            \n",
    "    def __call__(self, img) :\n",
    "        h, w, c = img.shape\n",
    "        \n",
    "        # step 1. resize width or height to 256 with preserve the original aspect ratio.\n",
    "        if h < w :\n",
    "            resized_w = int(w / h * 256)\n",
    "            img = cv2.resize(img, (256 , resized_w))\n",
    "\n",
    "        elif w <= h :\n",
    "            resized_h = int(h / w * 256)\n",
    "            img = cv2.resize(img, (resized_h, 256))\n",
    "        \n",
    "        # step 2. Random crop size 225 x 225\n",
    "        img = A.RandomCrop(225, 225)(image = img)['image']\n",
    "        \n",
    "        # step 3 and 4. split 3 x 3 grid of 75 x 75 pixels tiles and random crop 64 x 64\n",
    "        for i in range(3) :\n",
    "            for j in range(3) :\n",
    "                crop_img = img[i*75 : (i * 75) + 75, j*75 : (j * 75) + 75, :]\n",
    "                crop_img = A.RandomCrop(64,64)(image = crop_img)['image']\n",
    "                \n",
    "                if self.normalize :\n",
    "                    crop_img_m = [crop_img[:, :, i] for i in range(3)]\n",
    "                    crop_img_s = [crop_img[:, :, i] for i in range(3)]\n",
    "                    crop_img = A.Normalize(mean=crop_img_m, std=crop_img_s)(image=crop_img)['image']\n",
    "                \n",
    "                if i == 0 and j == 0 :    \n",
    "#                     tile_img = self.transforms(image = crop_img)['image']\n",
    "                    tile_img = crop_img\n",
    "                else : \n",
    "#                     tile_img = np.concatenate((tile_img,self.transforms(image = crop_img)['image']),axis=2)\n",
    "                    tile_img = np.concatenate((tile_img, crop_img), axis=2)\n",
    "        \n",
    "        return tile_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a24462",
   "metadata": {},
   "source": [
    "## Generate Permutation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54714ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutation_sets(number_permu_set=100, max_hamming=True, save=True) :\n",
    "\n",
    "    item = [i for i in range(1,10)]\n",
    "    permutate_items = np.array(list(permutations(item, 9)))\n",
    "    max_hamming = True\n",
    "\n",
    "    N = number_permu_set # permutation 개수\n",
    "    j = np.random.choice(len(permutate_items), 1, replace=False)\n",
    "\n",
    "    for i in tqdm(range(1, N+1)) :\n",
    "        if i == 1 :\n",
    "            p = np.array(permutate_items[j])\n",
    "        else : \n",
    "            hat_p = np.array(permutate_items[j]).reshape([1, -1])\n",
    "            p = np.concatenate([p, hat_p], axis=0)\n",
    "\n",
    "        permutate_items = np.delete(permutate_items, j, axis=0)\n",
    "        d = distance.cdist(p, permutate_items, metric='hamming').mean(axis=0)\n",
    "\n",
    "        if max_hamming == True :\n",
    "            j = np.argmax(d)\n",
    "        else : \n",
    "            j = np.argmin(d)\n",
    "            \n",
    "    if save :\n",
    "        np.save(f'permutation_{N}_sets.npy', p)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d81aa9",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6af1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JIGSAW_DATASET(Dataset) :\n",
    "    def __init__(self, img_list, permu_set, normalize=True) :\n",
    "        self.img_list = img_list\n",
    "        self.permu_set = permu_set\n",
    "        self.pipeline = jigsaw_pipeline(normalize=normalize)\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def shuffle_tiles(self, tile, permu):\n",
    "        shuffled_tile = np.zeros_like(tile)\n",
    "        for idx, num in enumerate(permu, start=1) :\n",
    "            shuffled_tile[:, :, (idx-1)*3 : idx*3] = tile[:, :, (num-1) * 3 : num * 3]\n",
    "        return shuffled_tile\n",
    "            \n",
    "    def __getitem__(self, idx) :\n",
    "        img = cv2.imread(self.img_list[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.pipeline(img)\n",
    "        \n",
    "        permu_idx = np.random.randint(self.permu_set.shape[0])        \n",
    "        permu = self.permu_set[permu_idx]\n",
    "        \n",
    "        img = self.shuffle_tiles(img, permu)\n",
    "        img = img.transpose(2,0,1)\n",
    "\n",
    "        return torch.FloatTensor(img), torch.tensor(permu_idx, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a50399d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6da059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _accuracy(pred, label) :\n",
    "    idx_pred = torch.argmax(pred, dim=1)\n",
    "    acc = idx_pred == label\n",
    "    return acc.sum() / acc.shape[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c83cc84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(args) :\n",
    "    model = CFN(in_feature=1024, num_classes=args.num_classes).to(args.device)\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=args.learning_rate)\n",
    "    criterion  = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    ps = np.load(args.permutation_path)\n",
    "    img_list = glob(args.img_path)\n",
    "    \n",
    "    jigsaw_dataset = JIGSAW_DATASET(img_list, ps, normalize=args.normalize)\n",
    "    dataloader = DataLoader(jigsaw_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "    for E in range(1, args.epochs+1) :\n",
    "        avg_loss, avg_acc = 0, 0\n",
    "        for img, label in dataloader:\n",
    "            model.train()\n",
    "            img = img.to(args.device)\n",
    "            label = label.to(args.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, label)\n",
    "            acc = _accuracy(pred.cpu(), label.cpu())\n",
    "            \n",
    "            avg_loss += loss.cpu().item()\n",
    "            avg_acc += acc.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Epochs :\", E, f\" || ACC : {avg_acc/len(dataloader):0.4f}  ||  Loss : {avg_loss/len(dataloader):0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef68815",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7069c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Options = {\n",
    "    'permutation_path' : './permutation_sets/permutation_3_sets.npy',\n",
    "    'batch_size' : 64,\n",
    "    'epochs' : 70,\n",
    "    'learning_rate' : 0.01,\n",
    "    'normalize' : False,\n",
    "    'device' : \"cuda:0\",\n",
    "    \"img_path\" : './_data/*',\n",
    "    \"num_classes\" : 3 # should be same as number of permutations set\n",
    "}\n",
    "args = EasyDict(Options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f788dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 1  || ACC : 0.3190  ||  Loss : 1.1092\n",
      "Epochs : 2  || ACC : 0.3919  ||  Loss : 1.0945\n",
      "Epochs : 3  || ACC : 0.3177  ||  Loss : 1.1386\n",
      "Epochs : 4  || ACC : 0.3750  ||  Loss : 1.1147\n",
      "Epochs : 5  || ACC : 0.3555  ||  Loss : 1.1011\n",
      "Epochs : 6  || ACC : 0.3984  ||  Loss : 1.0900\n",
      "Epochs : 7  || ACC : 0.3411  ||  Loss : 1.1039\n",
      "Epochs : 8  || ACC : 0.3516  ||  Loss : 1.1021\n",
      "Epochs : 9  || ACC : 0.4049  ||  Loss : 1.0801\n",
      "Epochs : 10  || ACC : 0.3281  ||  Loss : 1.1106\n",
      "Epochs : 11  || ACC : 0.4232  ||  Loss : 1.0762\n",
      "Epochs : 12  || ACC : 0.4023  ||  Loss : 1.0892\n",
      "Epochs : 13  || ACC : 0.4284  ||  Loss : 1.0798\n",
      "Epochs : 14  || ACC : 0.4414  ||  Loss : 1.0807\n",
      "Epochs : 15  || ACC : 0.4557  ||  Loss : 1.0493\n",
      "Epochs : 16  || ACC : 0.5703  ||  Loss : 1.0216\n",
      "Epochs : 17  || ACC : 0.4271  ||  Loss : 1.1008\n",
      "Epochs : 18  || ACC : 0.5469  ||  Loss : 1.0035\n",
      "Epochs : 19  || ACC : 0.5586  ||  Loss : 0.9686\n",
      "Epochs : 20  || ACC : 0.4674  ||  Loss : 1.1006\n",
      "Epochs : 21  || ACC : 0.4635  ||  Loss : 0.9835\n",
      "Epochs : 22  || ACC : 0.5885  ||  Loss : 0.9567\n",
      "Epochs : 23  || ACC : 0.5430  ||  Loss : 0.9572\n",
      "Epochs : 24  || ACC : 0.6458  ||  Loss : 0.8942\n",
      "Epochs : 25  || ACC : 0.7240  ||  Loss : 0.7786\n",
      "Epochs : 26  || ACC : 0.6367  ||  Loss : 0.9535\n",
      "Epochs : 27  || ACC : 0.6966  ||  Loss : 0.7735\n",
      "Epochs : 28  || ACC : 0.6315  ||  Loss : 0.9280\n",
      "Epochs : 29  || ACC : 0.5859  ||  Loss : 0.9424\n",
      "Epochs : 30  || ACC : 0.6081  ||  Loss : 0.8437\n",
      "Epochs : 31  || ACC : 0.8750  ||  Loss : 0.4985\n",
      "Epochs : 32  || ACC : 0.4596  ||  Loss : 1.4770\n",
      "Epochs : 33  || ACC : 0.3750  ||  Loss : 1.0592\n",
      "Epochs : 34  || ACC : 0.5052  ||  Loss : 1.0087\n",
      "Epochs : 35  || ACC : 0.4518  ||  Loss : 1.0802\n",
      "Epochs : 36  || ACC : 0.5482  ||  Loss : 0.9495\n",
      "Epochs : 37  || ACC : 0.5299  ||  Loss : 1.0000\n",
      "Epochs : 38  || ACC : 0.5247  ||  Loss : 0.9067\n",
      "Epochs : 39  || ACC : 0.5091  ||  Loss : 0.8911\n",
      "Epochs : 40  || ACC : 0.5495  ||  Loss : 0.9697\n",
      "Epochs : 41  || ACC : 0.5182  ||  Loss : 1.0309\n",
      "Epochs : 42  || ACC : 0.7018  ||  Loss : 0.8210\n",
      "Epochs : 43  || ACC : 0.6315  ||  Loss : 0.8946\n",
      "Epochs : 44  || ACC : 0.6393  ||  Loss : 0.8267\n",
      "Epochs : 45  || ACC : 0.7826  ||  Loss : 0.5840\n",
      "Epochs : 46  || ACC : 0.4935  ||  Loss : 1.1698\n",
      "Epochs : 47  || ACC : 0.6927  ||  Loss : 0.7755\n",
      "Epochs : 48  || ACC : 0.7839  ||  Loss : 0.6213\n",
      "Epochs : 49  || ACC : 0.5365  ||  Loss : 1.2100\n",
      "Epochs : 50  || ACC : 0.7630  ||  Loss : 0.6966\n",
      "Epochs : 51  || ACC : 0.7396  ||  Loss : 0.7536\n",
      "Epochs : 52  || ACC : 0.7799  ||  Loss : 0.6107\n",
      "Epochs : 53  || ACC : 0.7682  ||  Loss : 0.5755\n",
      "Epochs : 54  || ACC : 0.7005  ||  Loss : 0.8268\n",
      "Epochs : 55  || ACC : 0.7656  ||  Loss : 0.6125\n",
      "Epochs : 56  || ACC : 0.8190  ||  Loss : 0.4805\n",
      "Epochs : 57  || ACC : 0.8125  ||  Loss : 0.5067\n",
      "Epochs : 58  || ACC : 0.6068  ||  Loss : 1.0495\n",
      "Epochs : 59  || ACC : 0.5599  ||  Loss : 0.9099\n",
      "Epochs : 60  || ACC : 0.7578  ||  Loss : 0.6644\n",
      "Epochs : 61  || ACC : 0.8008  ||  Loss : 0.5045\n",
      "Epochs : 62  || ACC : 0.8750  ||  Loss : 0.3589\n",
      "Epochs : 63  || ACC : 0.7552  ||  Loss : 0.5865\n",
      "Epochs : 64  || ACC : 0.7773  ||  Loss : 0.5612\n",
      "Epochs : 65  || ACC : 0.8190  ||  Loss : 0.4389\n",
      "Epochs : 66  || ACC : 0.8893  ||  Loss : 0.3057\n",
      "Epochs : 67  || ACC : 0.8047  ||  Loss : 0.5609\n",
      "Epochs : 68  || ACC : 0.7435  ||  Loss : 0.6388\n",
      "Epochs : 69  || ACC : 0.9036  ||  Loss : 0.2862\n",
      "Epochs : 70  || ACC : 0.7865  ||  Loss : 0.4607\n"
     ]
    }
   ],
   "source": [
    "training(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4578e",
   "metadata": {},
   "source": [
    "### 문제점\n",
    "##### normalize 를 하면 성능이 안좋아짐. weight 값이 Nan으로 가버림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753f878a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
